# Codebase Structure

**Analysis Date:** 2025-02-24

## Directory Layout

```
D:/Shift-GCN/
├── config/                          # Training configuration files (YAML)
│   ├── mediapipe/                  # MediaPipe 33-landmark configs
│   │   ├── train_joint.yaml
│   │   ├── train_bone.yaml
│   │   ├── train_joint_motion.yaml
│   │   └── train_bone_motion.yaml
│   ├── nturgbd-cross-subject/      # NTU 25-joint cross-subject split configs
│   └── nturgbd-cross-view/         # NTU 25-joint cross-view split configs
│
├── data/                            # Training/validation skeleton data (auto-generated)
│   ├── mediapipe/                  # MediaPipe extracted data
│   │   ├── train_data_joint.npy
│   │   ├── train_data_bone.npy
│   │   ├── train_data_joint_motion.npy
│   │   ├── train_data_bone_motion.npy
│   │   ├── train_label.pkl
│   │   ├── val_data_joint.npy
│   │   ├── val_data_bone.npy
│   │   ├── val_data_joint_motion.npy
│   │   ├── val_data_bone_motion.npy
│   │   └── val_label.pkl
│   ├── nturgbd_raw/                # NTU RGB-D raw skeleton files
│   └── nturgbd120_raw/             # NTU RGB-D 120 raw skeleton files
│
├── data_gen/                        # Data generation and preprocessing
│   ├── mediapipe_gendata.py         # Extract landmarks from videos, class balance
│   ├── gen_bone_data_mediapipe.py   # Generate bone (joint-diff) modality
│   ├── gen_motion_data_mediapipe.py # Generate motion (frame-diff) modality
│   ├── preprocess.py                # Skeleton normalization (centering, rotation)
│   ├── rotation.py                  # 3D rotation matrices for alignment
│   ├── ntu_gendata.py               # NTU RGB+D raw skeleton data generation
│   ├── ntu120_gendata.py            # NTU RGB+D 120 data generation
│   ├── gen_bone_data.py             # NTU bone modality
│   ├── gen_motion_data.py           # NTU motion modality
│   └── __init__.py
│
├── feeders/                         # Data loading and augmentation
│   ├── feeder.py                    # Feeder class (PyTorch Dataset)
│   ├── tools.py                     # Augmentation utilities (shift, padding, etc.)
│   └── __init__.py
│
├── graph/                           # Skeleton topology definitions
│   ├── ntu_rgb_d.py                 # NTU RGB-D graph (25 joints)
│   ├── mediapipe_pose.py            # MediaPipe Pose graph (33 landmarks)
│   ├── tools.py                     # Graph construction (adjacency matrices)
│   └── __init__.py
│
├── model/                           # Model architecture and CUDA ops
│   ├── shift_gcn.py                 # Shift_gcn, Shift_tcn, TCN_GCN_unit, Model
│   ├── __init__.py
│   └── Temporal_shift/
│       ├── cuda/
│       │   ├── shift.py              # CUDA shift operation Python wrapper
│       │   ├── shift_cuda_linear.cpp # C++ CUDA kernel source
│       │   ├── setup.py              # Build script for CUDA extension
│       │   ├── __init__.py
│       │   └── build/                # Compiled binaries (auto-generated)
│       └── demo.py
│
├── save_models/                     # Saved model checkpoints (auto-generated)
│   ├── mediapipe_ShiftGCN_joint-*.pt
│   ├── mediapipe_ShiftGCN_bone-*.pt
│   ├── mediapipe_ShiftGCN_joint_motion-*.pt
│   └── mediapipe_ShiftGCN_bone_motion-*.pt
│
├── work_dir/                        # Training logs and evaluation results
│   ├── mediapipe_ShiftGCN_joint/
│   │   ├── log.txt                  # Training log (stdout capture)
│   │   ├── config.yaml              # Saved config for reproducibility
│   │   └── eval_results/
│   │       ├── best_acc.pkl         # Best model output logits
│   │       └── epoch_*.pkl          # Per-epoch output logits
│   ├── mediapipe_ShiftGCN_bone/
│   ├── mediapipe_ShiftGCN_joint_motion/
│   └── mediapipe_ShiftGCN_bone_motion/
│
├── main.py                          # Training/eval entry point (Processor)
├── ensemble_mediapipe.py            # 4-modality weighted ensemble + reporting
├── ensemble.py                      # Legacy multi-modality ensemble (NTU)
├── CLAUDE.md                        # Project instructions and commands
├── TRAINING_REPORT.md               # Results, epoch-by-epoch accuracy, F1
├── MEDIAPIPE_ADAPTATION_REPORT.md   # Technical adaptation details
└── README.md                        # Original project README
```

## Directory Purposes

**config/mediapipe/**
- Purpose: Centralized YAML training configurations for 4 modalities (joint, bone, joint_motion, bone_motion)
- Contains: Model args (num_point=33, graph), data paths, optimizer settings (lr, step), batch size, num_epoch
- Key files: All 4 YAML files have identical hyperparams (batch=64, lr=0.1, step=[60,80,100], num_epoch=140)

**data/mediapipe/**
- Purpose: Training and validation skeleton data in numpy/pickle format
- Contains: (N, C, T, V, M) arrays where N=sample count, C=3 (x,y,z), T=frames, V=joints, M=persons
- Generated by: `mediapipe_gendata.py` → `gen_bone_data_mediapipe.py` → `gen_motion_data_mediapipe.py`
- File pattern: `{train,val}_data_{joint,bone,joint_motion,bone_motion}.npy`, `{train,val}_label.pkl`

**data_gen/**
- Purpose: Skeleton extraction from raw video/sensor data and preprocessing
- Contains: Video-to-skeleton pipelines, normalization (centering, rotation), augmentation
- Pipeline: mediapipe_gendata.py (extract) → preprocess.py (normalize) → gen_bone_data_mediapipe.py (derive)

**feeders/**
- Purpose: PyTorch DataLoader integration; per-sample augmentation during training
- Contains: Feeder class (Dataset interface), augmentation functions (random shift, padding, rotation)
- Key: Supports lazy loading via mmap, debug mode (first 100 samples), normalization

**graph/**
- Purpose: Define skeleton connectivity for input shape validation and preprocessing
- Contains: Joint definitions (inward/outward edges), adjacency matrix computation
- Note: Graph NOT used in Shift_gcn convolution (shift replaces spatial GCN)

**model/**
- Purpose: Core neural network architecture
- Contains: Shift_gcn (spatial feature extraction), Shift_tcn (temporal), TCN_GCN_unit (combined), Model (full stack)
- CUDA dependency: `cuda/shift.py` provides learnable temporal shifting (requires GPU)

**save_models/**
- Purpose: Store trained model checkpoints
- Format: Dictionary with keys `{model_state_dict, optimizer_state_dict, epoch, global_step, best_acc}`
- Naming: `{Experiment_name}-{epoch}-{global_step}.pt`

**work_dir/**
- Purpose: Logging and per-model evaluation artifacts
- Contains: `log.txt` (training progress), `config.yaml` (saved config), `eval_results/*.pkl` (output logits per epoch)
- Used by: `ensemble_mediapipe.py` to load best model outputs for ensemble inference

## Key File Locations

**Entry Points:**
- `main.py`: Main training/eval orchestrator; parses config, instantiates Processor, runs train/eval loops
- `ensemble_mediapipe.py`: 4-modality ensemble; loads best outputs from each model, reports accuracy and F1
- `data_gen/mediapipe_gendata.py`: Extracts MediaPipe landmarks from NTU RGB-D videos; applies class balancing

**Configuration:**
- `config/mediapipe/train_joint.yaml`: Example config (data paths, model args, hyperparams)
- `work_dir/{exp_name}/config.yaml`: Auto-saved config at training start (full resolved arg dict)

**Core Logic:**
- `model/shift_gcn.py`: Model class, TCN_GCN_unit, Shift_gcn, Shift_tcn layers
- `graph/mediapipe_pose.py`: MediaPipe 33-landmark topology definition
- `data_gen/preprocess.py`: Skeleton normalization (center, rotate to align z/x axes)
- `feeders/feeder.py`: Feeder dataset class; supports mmap, debug mode, augmentation

**Testing:**
- No dedicated test directory; validation via `test_feeder_args` in config (val set evaluation each epoch)
- Per-sample debugging: `feeders/feeder.py:106-150` (test() function for visualization)

## Naming Conventions

**Files:**
- Python modules: `snake_case.py` (e.g., `shift_gcn.py`, `mediapipe_gendata.py`)
- CUDA source: `snake_case.cpp/.h` (e.g., `shift_cuda_linear.cpp`)
- Config files: `train_{modality}.yaml` (e.g., `train_joint.yaml`)
- Checkpoint files: `{Experiment_name}-{epoch}-{global_step}.pt`
- Pickle outputs: `{epoch}_{accuracy}.pkl` or `best_acc.pkl`

**Directories:**
- Data splits: `{data_type}_data_{modality}.npy` + `{data_type}_label.pkl`
  - data_type: `train`, `val`
  - modality: `joint`, `bone`, `joint_motion`, `bone_motion`
- Work directories: `{Experiment_name}/` in `work_dir/` (matches config's Experiment_name)
- Model saves: `{Experiment_name}-{epoch}-{step}.pt` in `save_models/` (matches config's Experiment_name)

**Classes & Functions:**
- Class names: PascalCase (e.g., `Shift_gcn`, `TCN_GCN_unit`, `Model`, `Feeder`)
- Function names: snake_case (e.g., `extract_landmarks()`, `pre_normalization()`, `random_shift()`)
- Private/helper functions: Often prefixed with `_` or inline in class

## Where to Add New Code

**New Modality (e.g., velocity data):**
- Data generation: Create `data_gen/gen_velocity_data_mediapipe.py` following `gen_motion_data_mediapipe.py` pattern
- Config: Add `config/mediapipe/train_velocity.yaml` with same hyperparams, but different data path
- Training: Run `python main.py --config ./config/mediapipe/train_velocity.yaml`
- Ensemble: Update `ensemble_mediapipe.py` line 10-13 to load velocity model output, adjust alpha weights

**New Graph Topology (e.g., different skeleton format):**
- Definition: Create `graph/my_skeleton.py` with Graph class (like `mediapipe_pose.py`)
  - Must define: `num_node`, `self_link`, `inward`, `outward`, `neighbor`, `get_adjacency_matrix()`
- Model config: Set `graph: graph.my_skeleton.Graph` in YAML
- Data shape: Adjust `num_point` in config to match your skeleton's vertex count

**New Augmentation:**
- Implementation: Add function to `feeders/tools.py` (follow pattern of `random_shift`, `random_move`)
- Usage: Add flag to Feeder args in config, apply in `feeders/feeder.py:__getitem__` (lines 81-88)

**New Layer/Unit:**
- Implementation: Add class to `model/shift_gcn.py`
- Integration: Instantiate in Model.__init__, insert into forward path (currently l1-l10)
- Testing: Verify shapes at each step via `Model.forward()` comments (e.g., line 211-216)

**Utilities (preprocessing, metrics):**
- Shared preprocessing: `data_gen/preprocess.py` (already handles MediaPipe centering at [23,24])
- Per-sample transforms: `feeders/tools.py` for data augmentation
- Graph operations: `graph/tools.py` for adjacency matrix construction
- Metrics: Add to `ensemble_mediapipe.py` or new script using sklearn (e.g., classification_report, confusion_matrix)

## Special Directories

**model/Temporal_shift/cuda/:**
- Purpose: CUDA acceleration for temporal shift operation
- Generated: YES — `build/` subdirs are compiled binaries, not committed
- Committed: YES — `.cpp` source and `setup.py` build script are in git
- Build command: `cd model/Temporal_shift/cuda && python setup.py install`
- Windows specifics: Requires VS2022 + CUDA 12.6; conda's vcvars batch files patched for toolset discovery

**work_dir/:**
- Purpose: Training artifacts (logs, configs, per-epoch evaluations)
- Generated: YES — created by Processor at training start with `exist_ok=True`
- Committed: NO — only checkpoints in `save_models/` are committed
- Cleanup: `--overwrite True` removes old `.pt` and `eval_results/*.pkl` files before re-training

**data/mediapipe/**
- Purpose: Processed skeleton arrays (derived from raw NTU videos)
- Generated: YES — by `mediapipe_gendata.py` and downstream scripts
- Committed: NO — large binary files; reproducible from raw videos via data pipeline
- Reproducibility: Requires original NTU RGB+D video files; extraction is deterministic (fixed seed)

**save_models/:**
- Purpose: Model checkpoints for resuming training or inference
- Generated: YES — saved at intervals during training via `main.py:441-448`
- Committed: SELECTIVELY — best models committed, old checkpoints cleaned with `--overwrite True`
- Format: Dictionary checkpoint with full training state (model + optimizer + epoch)

---

*Structure analysis: 2025-02-24*
